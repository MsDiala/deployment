{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('Train-set.csv')\n",
    "test_data = pd.read_csv('Test-set.csv')\n",
    "\n",
    "# Separate the 'Target' column from the train data\n",
    "y_train = train_data['Target']\n",
    "train_data.drop('Target', axis=1, inplace=True)\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "all_data = pd.concat([train_data, test_data], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Extract day of the week and create a weekend indicator\n",
    "try:\n",
    "    all_data['day'] = pd.to_datetime(all_data['day'])\n",
    "    all_data['day_of_week'] = all_data['day'].dt.dayofweek\n",
    "    all_data['is_weekend'] = all_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "    all_data.drop('day', axis=1, inplace=True)\n",
    "except (ValueError, OverflowError, pd._libs.tslibs.np_datetime.OutOfBoundsDatetime):\n",
    "    # Handle errors due to invalid date formats\n",
    "    all_data['day'] = pd.to_datetime(all_data['day'], errors='coerce')\n",
    "    all_data['day_of_week'] = all_data['day'].dt.dayofweek\n",
    "    all_data['is_weekend'] = all_data['day_of_week'].isin([5, 6]).astype(int)\n",
    "    all_data.drop('day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_cols = all_data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = all_data.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Create transformers for numeric and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocess the data using the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "X_all_preprocessed = preprocessor.fit_transform(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance using BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_all_preprocessed[:train_data.shape[0]], y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train optimized models\n",
    "optimized_rf_model = RandomForestClassifier(n_estimators=150, max_depth=9, random_state=42)\n",
    "optimized_gb_model = GradientBoostingClassifier(n_estimators=160, learning_rate=0.05, max_depth=7, random_state=42)\n",
    "optimized_lgbm_model = LGBMClassifier(n_estimators=180, learning_rate=0.1, max_depth=5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using SelectFromModel\n",
    "feature_selector = SelectFromModel(optimized_rf_model)\n",
    "X_train_resampled_selected = feature_selector.fit_transform(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected feature indices\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected feature names from the preprocessed data\n",
    "selected_feature_names = [all_data.columns[i] for i in selected_feature_indices]\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"Selected Feature Names:\")\n",
    "print(selected_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature selection to test data as well\n",
    "X_test_selected = X_all_preprocessed[train_data.shape[0]:, selected_feature_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train optimized models on selected features\n",
    "optimized_rf_model.fit(X_train_resampled_selected, y_train_resampled)\n",
    "optimized_gb_model.fit(X_train_resampled_selected, y_train_resampled)\n",
    "optimized_lgbm_model.fit(X_train_resampled_selected, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions using optimized models on selected features\n",
    "test_predictions_rf = optimized_rf_model.predict_proba(X_test_selected)[:, 1]\n",
    "test_predictions_gb = optimized_gb_model.predict_proba(X_test_selected)[:, 1]\n",
    "test_predictions_lgbm = optimized_lgbm_model.predict_proba(X_test_selected)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the predictions using weighted averaging\n",
    "ensemble_predictions = (0.4 * test_predictions_rf) + (0.4 * test_predictions_gb) + (0.2 * test_predictions_lgbm)\n",
    "threshold = 0.5\n",
    "binary_predictions = (ensemble_predictions >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 'id' values from the test_data DataFrame\n",
    "submission_ids = test_data['id']\n",
    "\n",
    "# Create binary predictions based on a threshold (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "binary_predictions = (ensemble_predictions >= threshold).astype(int)\n",
    "\n",
    "# Create the submission DataFrame with 'id' and binary 'Target' values\n",
    "submission_df = pd.DataFrame({'id': submission_ids, 'Target': binary_predictions})\n",
    "\n",
    "# Save the submission file to CSV\n",
    "submission_df.to_csv('submission_binary_updated.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('Train-set.csv')\n",
    "test_data = pd.read_csv('Test-set.csv')\n",
    "\n",
    "# Separate the 'Target' column from the train data\n",
    "y_train = train_data['Target']\n",
    "train_data.drop('Target', axis=1, inplace=True)\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "all_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = all_data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = all_data.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Create transformers for numeric and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocess the data using the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "X_all_preprocessed = preprocessor.fit_transform(all_data)\n",
    "\n",
    "# Handle class imbalance using BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_all_preprocessed[:train_data.shape[0]], y_train)\n",
    "\n",
    "# Initialize and train a feature selection model\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=150, max_depth=9, random_state=42))\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_numeric_feature_names = np.array(numeric_cols)[selected_feature_indices[selected_feature_indices < len(numeric_cols)]]\n",
    "\n",
    "# Get the OneHotEncoder used for categorical columns\n",
    "categorical_encoder = preprocessor.named_transformers_['cat']['encoder']\n",
    "\n",
    "# Get selected categorical feature names\n",
    "selected_categorical_feature_names = categorical_encoder.get_feature_names(input_features=categorical_cols)\n",
    "selected_categorical_feature_names = [name for i, name in enumerate(selected_categorical_feature_names) if i + len(numeric_cols) in selected_feature_indices]\n",
    "\n",
    "# Concatenate selected feature names\n",
    "selected_feature_names = np.concatenate((selected_numeric_feature_names, selected_categorical_feature_names))\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"Selected Feature Names:\")\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('Train-set.csv')\n",
    "test_data = pd.read_csv('Test-set.csv')\n",
    "\n",
    "# Separate the 'Target' column from the train data\n",
    "y_train = train_data['Target']\n",
    "train_data.drop('Target', axis=1, inplace=True)\n",
    "\n",
    "# Combine train and test data for preprocessing\n",
    "all_data = pd.concat([train_data, test_data], axis=0)\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = all_data.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = all_data.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Create transformers for numeric and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocess the data using the column transformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n",
    "X_all_preprocessed = preprocessor.fit_transform(all_data)\n",
    "\n",
    "# Handle class imbalance using BorderlineSMOTE\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_all_preprocessed[:train_data.shape[0]], y_train)\n",
    "\n",
    "# Initialize and train a feature selection model\n",
    "selector = SelectFromModel(RandomForestClassifier(n_estimators=150, max_depth=9, random_state=42))\n",
    "selector.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get selected feature indices\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_numeric_feature_names = np.array(numeric_cols)[selected_feature_indices[selected_feature_indices < len(numeric_cols)]]\n",
    "\n",
    "# Retrieve the OneHotEncoder used for categorical columns\n",
    "categorical_encoder = preprocessor.named_transformers_['cat']['encoder']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the OneHotEncoder used for categorical columns\n",
    "categorical_encoder = preprocessor.named_transformers_['cat']['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and get the column names after one-hot encoding\n",
    "onehot_columns = categorical_encoder.get_feature_names_out(input_features=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected categorical feature names\n",
    "selected_categorical_feature_names = []\n",
    "for i, col_idx in enumerate(selected_feature_indices):\n",
    "    if col_idx >= len(numeric_cols):\n",
    "        selected_categorical_feature_names.append(onehot_columns[col_idx - len(numeric_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate selected feature names\n",
    "selected_feature_names = np.concatenate((selected_numeric_feature_names, selected_categorical_feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Feature Names:\n",
      "['Unnamed: 0' 'age' 'duration' 'campaign' 'pdays' 'previous'\n",
      " 'job_blue-collar' 'marital_single' 'default_no' 'housing_no'\n",
      " 'housing_yes' 'loan_no' 'loan_yes' 'contact_cellular' 'contact_telephone'\n",
      " 'contact_unknown' 'day_may' 'month_may' 'poutcome_success']\n"
     ]
    }
   ],
   "source": [
    "# Print the selected feature names\n",
    "print(\"Selected Feature Names:\")\n",
    "print(selected_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
